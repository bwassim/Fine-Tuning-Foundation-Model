{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "I will try to use the sentiment analysis example introduced in the course but with the gpt-2\n",
    "\n",
    "* PEFT technique: \n",
    "    - LoRA (Low Rank Adaptation) technique will be my choice \n",
    "* Model: \n",
    "    - GPT-2 is the chosen model as recommended.\n",
    "* Evaluation approach: \n",
    "    - The `evaluate` and `Trainer` methods will be used for evaluation \n",
    "* Fine-tuning dataset: \n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5ff076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "# !pip install -q \"datasets==2.15.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "887665a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q \"scikit-learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "from transformers import AutoModelForSequenceClassification, Trainer\n",
    "from datasets import load_dataset, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7beaa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 7.81k/7.81k [00:00<00:00, 4.90MB/s]\n",
      "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  20%|██        | 4.19M/20.5M [00:00<00:01, 15.1MB/s]\u001b[A\n",
      "Downloading data:  61%|██████▏   | 12.6M/20.5M [00:00<00:00, 20.0MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 20.5M/20.5M [00:00<00:00, 22.8MB/s]\u001b[A\n",
      "Downloading data files:  33%|███▎      | 1/3 [00:00<00:01,  1.04it/s]\n",
      "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  20%|█▉        | 4.19M/21.0M [00:00<00:00, 28.7MB/s]\u001b[A\n",
      "Downloading data:  60%|█████▉    | 12.6M/21.0M [00:00<00:00, 46.2MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 21.0M/21.0M [00:00<00:00, 46.6MB/s]\u001b[A\n",
      "Downloading data files:  67%|██████▋   | 2/3 [00:01<00:00,  1.49it/s]\n",
      "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  10%|▉         | 4.19M/42.0M [00:00<00:01, 28.3MB/s]\u001b[A\n",
      "Downloading data:  30%|██▉       | 12.6M/42.0M [00:00<00:00, 45.6MB/s]\u001b[A\n",
      "Downloading data:  50%|████▉     | 21.0M/42.0M [00:00<00:00, 50.6MB/s]\u001b[A\n",
      "Downloading data:  70%|██████▉   | 29.4M/42.0M [00:00<00:00, 54.5MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 42.0M/42.0M [00:00<00:00, 52.8MB/s]\u001b[A\n",
      "Downloading data files: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 941.62it/s]\n",
      "Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 97520.18 examples/s]\n",
      "Generating train split: 100%|██████████| 25000/25000 [00:00<00:00, 105002.61 examples/s]\n",
      "Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 108607.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 25000\n",
       " })]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the train and test split from the imdb dataset \n",
    "splits = [\"train\",\"test\"]\n",
    "data = load_dataset(\"imdb\", split=splits)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " })}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = {split: ds for split, ds in zip(splits, load_dataset(\"imdb\", split=splits))}\n",
    "\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(500))\n",
    "    \n",
    "ds\n",
    "\n",
    "# simpler way with from sklearn.model_selection import train_test_split\n",
    "# train_data, test_data = train_test_split(data[\"train\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8f6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(ds['train']['text'][0])\n",
    "print(ds['train']['label'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8cab0",
   "metadata": {},
   "source": [
    "### Preproceess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 500/500 [00:02<00:00, 244.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2Tokenizer\n",
    "\n",
    "# Specify model and tokenizer \n",
    "# Notice that gpt2 is well suited for language generation tasks. For sentiment analysis, using a \n",
    "# a model similar to the one used in the course (e.g distilbert-base-uncased) is more suitable.\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# \"Asking to pad but the tokenizer does not have a padding token. \"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_ds = {}\n",
    "\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(tokenize_function, batched=True)\n",
    "\n",
    "# train_data = train_data.map(tokenize_function, batched=True)\n",
    "# test_data = test_data.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b98f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e951dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 1671, 1220, 6927, 1671, 11037]\n"
     ]
    }
   ],
   "source": [
    "# print(tokenized_ds['test'][0]['input_ids'])\n",
    "print(tokenized_ds['test'][0]['input_ids'][:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd0ee7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8e1b0",
   "metadata": {},
   "source": [
    "### Foundation Model Training\n",
    "- Freeze all parameters before training \n",
    "- Train the last layer \n",
    "- Metric function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86df640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 548M/548M [00:02<00:00, 214MB/s] \n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load and setup the model \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
    "                                                          num_labels=2,\n",
    "                                                          id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "                                                          label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8507aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c63262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model's pad token to match that of the tokenizer.\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde549c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last leayer model classifier \n",
    "model.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47d78446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for Foundation model \n",
    "import numpy as np \n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Freeze the base model before training \n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6d4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Trainer and metric\n",
    "from transformers import TrainingArguments\n",
    "# metric = load_metric(\"accuracy\")\n",
    "\n",
    "training_args = TrainingArguments( \n",
    "            output_dir=\"./data/sentiment_analysis\",\n",
    "            learning_rate=2e-3,\n",
    "            weight_decay=0.01,\n",
    "            num_train_epochs= 1, \n",
    "            per_device_train_batch_size= 32,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            evaluation_strategy= \"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True)\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                args=training_args,\n",
    "                train_dataset=tokenized_ds['train'],\n",
    "                eval_dataset=tokenized_ds['test'],\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "                compute_metrics=compute_metrics\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9cc6cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.627621</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16, training_loss=0.968899667263031, metrics={'train_runtime': 90.0006, 'train_samples_per_second': 5.556, 'train_steps_per_second': 0.178, 'total_flos': 261296750592000.0, 'train_loss': 0.968899667263031, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the Foundation model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51419a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6276214122772217,\n",
       " 'eval_accuracy': 0.654,\n",
       " 'eval_runtime': 43.8711,\n",
       " 'eval_samples_per_second': 11.397,\n",
       " 'eval_steps_per_second': 0.365,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the performance of the trained model \n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "342f611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fa0f5",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- The eval accuracy of 0.56 is just slightly better than a random guess 0.5\n",
    "- let's see if we can do better with peft later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79210891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The eval accuracy is actually not significanlty as good as a random guess 0.5\n",
    "# Lets see if we can do better with peft later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c438d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I unsuspectedly rented A Thousand Acres...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the latest entry in the long series of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so frustrating. Everything seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was truly and wonderfully surprised at \"O' B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie spends most of its time preaching t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After a very long time Marathi cinema has come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a really sad, and touching movie! It d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Don't pay any attention to the rave reviews of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Porn legend Gregory Dark directs this cheesy h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This was a great movie. Something not only for...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0    When I unsuspectedly rented A Thousand Acres...      1                1\n",
       "1  This is the latest entry in the long series of...      1                1\n",
       "2  This movie was so frustrating. Everything seem...      0                0\n",
       "3  I was truly and wonderfully surprised at \"O' B...      1                1\n",
       "4  This movie spends most of its time preaching t...      0                1\n",
       "5  After a very long time Marathi cinema has come...      1                1\n",
       "6  This is a really sad, and touching movie! It d...      1                1\n",
       "7  Don't pay any attention to the rave reviews of...      0                1\n",
       "8  Porn legend Gregory Dark directs this cheesy h...      0                0\n",
       "9  This was a great movie. Something not only for...      1                1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some results \n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(tokenized_ds[\"test\"])\n",
    "df = df[[\"text\",\"label\"]]\n",
    "df['text'] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "lora_config = LoraConfig(\n",
    "#     r=3,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.1,\n",
    "#     target_modules=['c_attn','c_proj'],\n",
    "#     bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "# LoraConfig(\n",
    "# r=8, # Rank\n",
    "# lora_alpha=32,\n",
    "# target_modules=['c_attn', 'c_proj'],\n",
    "# lora_dropout=0.1,\n",
    "# bias=\"none\",\n",
    "# task_type=TaskType.SEQ_CLS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(50257, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): Linear(\n",
      "                in_features=768, out_features=2304, bias=True\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification\n",
    "model_peft = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    ")\n",
    "\n",
    "# Set the model's pad token id to match the tokenizer's pad token id\n",
    "model_peft.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_model = get_peft_model(model_peft, lora_config)\n",
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 297,984 || all params: 124,737,792 || trainable%: 0.23888830740245906\n"
     ]
    }
   ],
   "source": [
    "# check trainable parameter \n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae7716b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0928d7",
   "metadata": {},
   "source": [
    "## Train the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lora_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m train_args \u001b[38;5;241m=\u001b[39m TrainingArguments( \n\u001b[1;32m      2\u001b[0m             output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/sentiment_analysis_lora\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m             learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m             load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m trainer_lora \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m---> 14\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[43mlora_model\u001b[49m,\n\u001b[1;32m     15\u001b[0m         args\u001b[38;5;241m=\u001b[39mtrain_args,\n\u001b[1;32m     16\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mtokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m         eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     19\u001b[0m         data_collator\u001b[38;5;241m=\u001b[39mDataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer),\n\u001b[1;32m     20\u001b[0m         compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     21\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lora_model' is not defined"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments( \n",
    "            output_dir=\"./data/sentiment_analysis_lora\",\n",
    "            learning_rate=2e-3,\n",
    "            num_train_epochs= 1, \n",
    "            per_device_train_batch_size= 4,\n",
    "            per_device_eval_batch_size = 4,\n",
    "            weight_decay = 0.01,\n",
    "            evaluation_strategy= \"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            logging_dir='./logs')\n",
    "\n",
    "trainer_lora = Trainer(\n",
    "        model=lora_model,\n",
    "        args=train_args,\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72d8653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335916</td>\n",
       "      <td>0.866000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.8524192504882813, metrics={'train_runtime': 152.9476, 'train_samples_per_second': 3.269, 'train_steps_per_second': 0.817, 'total_flos': 262207438848000.0, 'train_loss': 0.8524192504882813, 'epoch': 1.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "trainer_lora.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da36ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3359161913394928,\n",
       " 'eval_accuracy': 0.866,\n",
       " 'eval_runtime': 46.1304,\n",
       " 'eval_samples_per_second': 10.839,\n",
       " 'eval_steps_per_second': 2.71,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model \n",
    "trainer_lora.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3bfa09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lora model(this will save the lora adapter weights only)\n",
    "lora_model.save_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcdf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 1.49MB/s]\n",
      "model.safetensors: 100%|██████████| 548M/548M [00:02<00:00, 202MB/s]  \n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved lora model \n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "lora_model_ = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(50257, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2Attention(\n",
      "              (c_attn): Linear(\n",
      "                in_features=768, out_features=2304, bias=True\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (c_proj): Conv1D()\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496,    11,   616,  1438,   318,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Generating text from PEFT Model \n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my name is \", return_tensors=\"pt\")\n",
    "# inputs\n",
    "training_args = TrainingArguments( \n",
    "            output_dir=\"./data/sentiment_analysis\",\n",
    "            learning_rate=2e-3,\n",
    "            weight_decay=0.01,\n",
    "            num_train_epochs= 1, \n",
    "            per_device_train_batch_size= 32,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            evaluation_strategy= \"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True)\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                args=training_args,\n",
    "                train_dataset=tokenized_ds['train'],\n",
    "                eval_dataset=tokenized_ds['test'],\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "                compute_metrics=compute_metrics\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a149180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: {'eval_loss': 1.4407130479812622, 'eval_accuracy': 0.49, 'eval_runtime': 43.3342, 'eval_samples_per_second': 11.538, 'eval_steps_per_second': 0.369}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Load the model\n",
    "lora_model_ = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt-lora\")\n",
    "lora_model_.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "   \n",
    "training_args = TrainingArguments( \n",
    "        output_dir=\"./data/sentiment_analysis_lora\",\n",
    "        per_device_eval_batch_size = 32,\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=lora_model_,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=tokenized_ds['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_results = trainer.evaluate(tokenized_ds[\"test\"])\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Test Accuracy:\", test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bffd375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I unsuspectedly rented A Thousand Acres...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the latest entry in the long series of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so frustrating. Everything seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was truly and wonderfully surprised at \"O' B...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie spends most of its time preaching t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After a very long time Marathi cinema has come...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a really sad, and touching movie! It d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Don't pay any attention to the rave reviews of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Porn legend Gregory Dark directs this cheesy h...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This was a great movie. Something not only for...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0    When I unsuspectedly rented A Thousand Acres...      1                1\n",
       "1  This is the latest entry in the long series of...      1                1\n",
       "2  This movie was so frustrating. Everything seem...      0                1\n",
       "3  I was truly and wonderfully surprised at \"O' B...      1                1\n",
       "4  This movie spends most of its time preaching t...      0                1\n",
       "5  After a very long time Marathi cinema has come...      1                1\n",
       "6  This is a really sad, and touching movie! It d...      1                1\n",
       "7  Don't pay any attention to the rave reviews of...      0                1\n",
       "8  Porn legend Gregory Dark directs this cheesy h...      0                1\n",
       "9  This was a great movie. Something not only for...      1                1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at some results \n",
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(tokenized_ds[\"test\"])\n",
    "df = df[[\"text\",\"label\"]]\n",
    "df['text'] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8088b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
